}
f2 <- function(x) {
y = 10
g2(x)
}
f2(10)
y <- 20
f2(10)
y <- 10
f2 <- function(x) {
y <- 10
g2(x)
}
g2 <- function(x) {
y + (x * x)
}
f2(10)
#### FACTORS ####
bloodgrp <- c("O", "A", "AB", "B", "A", "AB", "B", "O")
bloogrp_factor <- factor(bloodgrp, levels = c("A", "AB", "B", "O"))
bloodgrp_factpr
bloodgrp_factor
bloodgrp_factor <- factor(bloodgrp, levels = c("A", "AB", "B", "O"))
bloodgrp_factor
# [1] O  A  AB B  A  AB B  O
# Levels: A AB B O
bloodgrp_factor <- factor(bloodgrp, levels = c("A", "AB", "B", "O"), labels = c("BT_A", "BT_AB", "BT_B", "BT_O"))
bloodgrp_factor
dresssize_factor <- factor(dresssize, ordered = TRUE, levels = c("S", "M", "L"))
dresssize <- c("S", "M", "S", "L", "M", "L", "S", "L")
dresssize_factor <- factor(dresssize, ordered = TRUE, levels = c("S", "M", "L"))
dresssize_factor
# [1] S M S L M L S L
# Levels: S < M < L
dresssize_factor[1]
# [1] S M S L M L S L
# Levels: S < M < L
dresssize_factor[2]
sample(x=1:10, replace = TRUE)
sample(x=1:10, replace = TRUE)
sample(x=1:10, 1)
sample(x=1:10, 1)
sample(x=1:10, 1)
sample(x=1:10, 1)
sample(x=1:10, 1)
help(sample)
# Generate random numbers or sequence of random numbers
sample(x=1:10, size = n, replace = TRUE)
# Generate random numbers or sequence of random numbers
sample(x=1:10, size = 3, replace = TRUE)
# Generate random numbers or sequence of random numbers
sample(x=1:10, size = 3, replace = TRUE)
# Generate random numbers or sequence of random numbers
sample(x=1:10, size = 3, replace = FALSE) # by default, the size = n, where n is a positive number, the number of items to choose from
# Generate random numbers or sequence of random numbers
sample(x=1:10, size = 3, replace = FALSE) # by default, the size = n, where n is a positive number, the number of items to choose from
# Generate random numbers or sequence of random numbers
sample(x=1:10, size = 3, replace = FALSE) # by default, the size = n, where n is a positive number, the number of items to choose from
round(45.123456, 2) # Returns number rounded to 2 decimals
round(45.129456, 2) # Returns number rounded to 2 decimals
ceiling(5.03)
trunc(56.745)
trunc(56.999) # removes decimal places -- 56
log(2)
exp(0)
round(34.1234)
#### WORKING WITH DATES ####
Sys.Date() # Returns current system date
class(Sys.Date())
typeof(Sys.Date())
today
today <- Sys.Date()
today
typeof(today)
class(today)
today > Sys.Date() + 1
# Conversion of string to date
myDate <- as.Date("1990-11-03")
myDate
# Using format with date
# %b month abbreviated
# %d day of the month
# %y year in 2 digits
as.Date("Nov/03/1990", format="%b/%d/%y%y")
# %B full month name
# %Y year in 4 digits
as.Date("November-03-1994", format="%B-%d-%Y")
install.packages("nycflights13")
library(nycflights13)
View(flights)
head(flights)
# Subset dataset using filter()
f1 <- filter(flights, month == 7)
# Subset dataset using filter()
f1 <- filter(flights, month == 07)
# Subset dataset using filter()
f1 <- filter(flights, month==07)
# Subset dataset using filter()
f1 <- filter(flights, month==7)
# Subset dataset using filter()
f1 <- filter(flights, flights$month==7)
View(f1)
# Subset dataset using filter()
f1 <- filter(flights, flights$month==07)
View(f1)
f1
# Subset dataset using filter()
f1 <- dplyr::filter(flights, month==07)
View(f1)
f1 <- dplyr::filter(flights, month==07, day==3)
f1 <- dplyr::filter(flights, month==09, day==2, origin=="LGA")
# OR
f1 <- dplyr::filter(flights[flights$$month==09 & flights$day==2, ])
# OR
f1 <- dplyr::filter(flights[flights$month==09 & flights$day==2, ])
# slicing
dplyr::slice(flights, 1:5)
slice(flights, 5:10)
library(dplyr)
# Mutate() used to add new column
over_delay <- mutate(flights, overall_delay=arr_delay-dep_delay)
over_delay
View(over_delay)
# Transmute method - used to only create the new column
over_delay <- transmute(flights, overall_delay = arr_delay - dep_delay)
View(over_delay)
# summarise() method
summarise(flights, avg_air_time=mean(air_time, na.rm = TRUE))
summarise(flights, avg_air_time=sum(air_time, na.rm = TRUE))
summarise(flights, avg_air_time=mean(air_time, na.rm = TRUE), total_air_time=sum(air_time, na.rm=TRUE))
# Groupby
head(mtcars)
by_gear <- mtcars %>% group_by(gear)
by_gear
summarise(group_by(mtcars,cyl), mean(gear, na.rm = TRUE))
a <- summarise(by_gear, gear1=sum(gear, na.rm = TRUE), gear2=mean(gear, na.rm = TRUE))
a
# arrange() used to sort dataset
View(arrange(flights, year, dep_time))
# arrange() used to sort dataset
View(arrange(flights, day, dep_time))
# Nesting
result <- arrange(sample_n(filter(mtcars, mpg>20), size = 5))
result
# Nesting
result <- arrange(sample_n(filter(mtcars, mpg>20), size = 5), desc(mpg))
result
# Same using pipe operator
result <- mtcars %>% filter(mpg>20) %>% sample_n(size=10) %>% arrange(desc(mpg))
result
# select method
mpg_cyl_hp <- mtcars %>% select(mpg, cyl, hp)
head(mpg_cyl_hp)
#### tidyr package ####
install.packages("tidyr")
library(tidyr)
wide <- data.frame(
ID = c(1:n),
Face.1 = c(411, 723, 325, 456, 579, 612, 709, 513, 527, 379),
Face.2 = c(123, 300, 400, 500, 600, 654, 789, 906, 413, 567),
Face.3 = c(1457, 1000, 569, 896, 965, 2345, 780, 599, 1023, 678)
)
n = 10
wide <- data.frame(
ID = c(1:n),
Face.1 = c(411, 723, 325, 456, 579, 612, 709, 513, 527, 379),
Face.2 = c(123, 300, 400, 500, 600, 654, 789, 906, 413, 567),
Face.3 = c(1457, 1000, 569, 896, 965, 2345, 780, 599, 1023, 678)
)
View(wide)
# Gather method - reshaping data from wide format to long format
long <- wide %>% gather(Face, ResponseTime, Face.1:Face.3)
View(long)
View(wide)
# Gather method - reshaping data from wide format to long format
Face
# separate method - splits a single column into multiple columns
long_seperate <- long %>% separate(Face, c("Target", "Number"))
View(long_seperate)
wide <- data.frame(
ID = c(1:n),
Face.1.4 = c(411, 723, 325, 456, 579, 612, 709, 513, 527, 379),
Face.2.5 = c(123, 300, 400, 500, 600, 654, 789, 906, 413, 567),
Face.3.6 = c(1457, 1000, 569, 896, 965, 2345, 780, 599, 1023, 678)
)
# separate method - splits a single column into multiple columns
long_seperate <- long %>% separate(Face, c("Target", "Number"))
View(long_seperate)
View(wide)
# separate method - splits a single column into multiple columns
long_seperate <- long %>% separate(Face, c("Target", "Number1", "Number2"))
View(long_seperate)
wide <- data.frame(
ID = c(1:n),
Face.1 = c(411, 723, 325, 456, 579, 612, 709, 513, 527, 379),
Face.2 = c(123, 300, 400, 500, 600, 654, 789, 906, 413, 567),
Face.3 = c(1457, 1000, 569, 896, 965, 2345, 780, 599, 1023, 678)
)
# separate method - splits a single column into multiple columns
long_seperate <- long %>% separate(Face, c("Target", "Number"))
View(long_seperate)
wide <- data.frame(
ID = c(1:n),
Face.1.4 = c(411, 723, 325, 456, 579, 612, 709, 513, 527, 379),
Face.2.5 = c(123, 300, 400, 500, 600, 654, 789, 906, 413, 567),
Face.3.6 = c(1457, 1000, 569, 896, 965, 2345, 780, 599, 1023, 678)
)
# Gather method - reshaping data from wide format to long format
# Here, Face & ResponseTime are the names of the columns
# Face will take values like Face.1, Face.2
# ResponseTime will store the value of each Face.1 or Face.2 or Face.3
long <- wide %>% gather(Face, ResponseTime, Face.1.4:Face.3.6)
View(long)
# separate method - splits a single column into multiple columns
long_seperate <- long %>% separate(Face, c("Target", "Number"))
View(long_seperate)
View(long)
# separate method - splits a single column into multiple columns
long_seperate <- long %>% separate(Face, c("Target", "Number", "VALUE"))
View(long_seperate)
wide <- data.frame(
ID = c(1:n),
Face.1 = c(411, 723, 325, 456, 579, 612, 709, 513, 527, 379),
Face.2 = c(123, 300, 400, 500, 600, 654, 789, 906, 413, 567),
Face.3 = c(1457, 1000, 569, 896, 965, 2345, 780, 599, 1023, 678)
)
# Gather method - reshaping data from wide format to long format
# Here, Face & ResponseTime are the names of the columns
# Face will take values like Face.1, Face.2
# ResponseTime will store the value of each Face.1 or Face.2 or Face.3
long <- wide %>% gather(Face, ResponseTime, Face.1:Face.3)
# separate method - splits a single column into multiple columns
long_seperate <- long %>% separate(Face, c("Target", "Number"))
# Unite method - combines multiple columns into single column
long_unite <- long_seperate %>% unite(Face, Target, Number, sep=".")
View(long_unite)
View(long_unite)
# spread method - takes two columns (key & value) and spreads in to multiple columns
# makes data wider
back_to_wide <- long_unite %>% spread(Face, ResponseTime)
View(back_to_wide)
library(datasets)
plot(ChickWeight)
# base graphics
library(MASS)
plot(UScereal$sugars, UScereal$calories)
title("plot(UScereal$sugars, UScereal$calories)")
x <- UScereal$sugars
y <- UScereal$calories
library(grid)
# Grid graphics
pushViewport(plotViewport())
pushViewport(dataViewport(x, y))
grid.rect()
grid.xaxis()
grid.yaxis()
grid.points(x, y)
grid.text("UScereal$calories", x = unit(-3, "lines"), rot = 90)
# Grid graphics
pushViewport(plotViewport())
pushViewport(dataViewport(x, y))
grid.rect()
grid.xaxis()
grid.yaxis()
grid.points(x, y)
grid.text("UScereal$calories", x = unit(-3, "lines"), rot = 90)
grid.text("UScereal$sugars", y = unit(-3, "lines"), rot = 0)
plot(UScereal$sugars, UScereal$calories)
title("plot(UScereal$sugars, UScereal$calories)")
x <- UScereal$sugars
y <- UScereal$calories
library(grid)
# Grid graphics
pushViewport(plotViewport())
pushViewport(dataViewport(x, y))
grid.rect()
grid.xaxis()
grid.yaxis()
grid.points(x, y)
grid.text("UScereal$calories", x = unit(-3, "lines"), rot = 90)
grid.text("UScereal$sugars", y = unit(-3, "lines"), rot = 0)
grid.circle()
# Grid graphics
pushViewport(plotViewport())
pushViewport(dataViewport(x, y))
grid.circle()
grid.xaxis()
grid.yaxis()
grid.points(x, y)
# base graphics
library(MASS)
plot(UScereal$sugars, UScereal$calories)
title("plot(UScereal$sugars, UScereal$calories)")
# 3D pie charts
install.packages("plotrix")
# 3D pie charts
library(plotrix)
x <- c(33, 45, 70, 110)
lbl <- c("Soap", "Detergent", "Oil", "Shampoo")
pie3D(x, labels=lbl, explore=0.1, main="Pie chart of countries")
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk-18.0.1.1")
Sys.getenv("JAVA_HOME")
library(rpart)
library(caret)
library(rpart.plot)
library(dplyr)
library(data.tree)
library(caTools)
install.packages("ElemStatLearn")
R -version
R.version()
R.Version()
R --version
install.packages("installr")
library(installr)
updateR()
sample(seq(as.Date('1999/01/01'), as.Date('2000/01/01'), by="day"), 12)
test <- sample(seq(as.Date('1999/01/01'), as.Date('2000/01/01'), by="day"), 12)
sort(test)
test
test
test
sort(test)
for (i in test) {
print(i)
}
for (i in test) {print(as.Date(i))}
as.Date(10931)
as.Date(10931, origin = "IST")
test
test[1]
test[2]
# Library import
library(e1071)
library(caTools)
# Utilizing the inbuild dataset provided by R
plot(iris)
# plotting and color coding species
plot(iris$Sepal.Length, iris$Sepal.Width, col = iris$Species) # The data points are not scattered according to class. Thus, creating ideal hyperlane is not possible in linear SVM
plot(iris$Petal.Length, iris$Petal.Width, col = iris$Species) # The data is mostly scattered according to class, but there are few data points that are overlapping
# Sampling data set
sample <- sample.split(iris, SplitRatio = 0.7)
col <- c("Petal.Length", "Petal.Width", "Species")
train <- subset(iris, sample == TRUE)[, col]
test <- subset(iris, sample == FALSE)[, col]
# Model Generation
svmFit <- svm(Species ~., data = train, kernel = "linear", cost = 100, scale = FALSE)
print(svmFit)
# plot model
plot(svmFit, train[, col])
# Tuning the model for getting the best parameters
tuneModel <- tune(svm, Species ~., data = train, kernel = "linear", ranges = list(cost = c(0.001, 0.01, 0.1, 1, 10, 100)))
summary(tuneModel)
# Prediction
p <- predict(svmFit, test, type = "class")
plot(p)
# Cross check predictions
table(p, test[,3])
# Accuracy
mean(p == test[, 3])
# Random sample
randomSample <- iris[sample(1:nrow(iris), size = 1), col]
samplePrediction <- predict(svmFit, randomSample, type = "response")
print(as.character(samplePrediction))
View(randomSample)
iris
print(as.character(samplePrediction))
# Random sample
randomSample <- iris[sample(1:nrow(iris), size = 1), col]
samplePrediction <- predict(svmFit, randomSample, type = "response")
print(as.character(samplePrediction))
View(randomSample)
library(e1071)
?svn
?svm
iris$Sepal.Length
iris["Sepal.Length"]
library(factoextra)
?fviz_cluster
setwd("D:/Study/Learning/R/ML Course/SupportVectorMachine")
# Set Environment JAVA_HOME
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk-18.0.1.1")
# Importing libraries
library(randomForest)
library(caTools)
# Extracting data
wineData <- read.csv("WineQT.csv")
# Removing ID
wineData <- subset(wineData, select = -c(Id))
# Munging data
wineData$quality <- as.factor(wineData$quality)
# Splitting dataset
split <- caTools::sample.split(wineData, SplitRatio = 0.80)
trainData <- subset(wineData, split == TRUE)
testData <- subset(wineData, split == FALSE)
setwd("D:/Study/Learning/R/ML Course/RandomForest")
# Set Environment JAVA_HOME
Sys.setenv(JAVA_HOME = "C:\\Program Files\\Java\\jdk-18.0.1.1")
# Importing libraries
library(randomForest)
library(caTools)
# Extracting data
wineData <- read.csv("WineQT.csv")
# Removing ID
wineData <- subset(wineData, select = -c(Id))
# Munging data
wineData$quality <- as.factor(wineData$quality)
# Splitting dataset
split <- caTools::sample.split(wineData, SplitRatio = 0.80)
trainData <- subset(wineData, split == TRUE)
testData <- subset(wineData, split == FALSE)
# Generating random forest model
rfModel <- randomForest(quality ~ ., data = trainData, mtry = 4, ntree = 2001, importance = TRUE)
# Plotting
plot(rfModel)
# This shows, actual value v/s predicted value
result <- data.frame(testData$quality, predict(rfModel, testData, type = "response"))
print(result)
View(result)
View(wineData)
?write_csv
?write.csv
output <- data.frame(
AccountNumber <- 1234,
InBound <- TRUE,
DiffAggAvg <- 1234,
MinSd <- 1234,
MaxSd <- 12,
AggAmount <- 12,
AvgAmountPercentageIncrease <- 12,
FP <- 1
)
output
names(output) <- c("AccountNumber", "InBound","DiffAggAvg", "MinSd", "MaxSd", "AggAmount", "AvgAmountPercentageIncrease", "FP")
output
write.csv(output, "D:\Study\ITM\IIP\CIB - Task\Data\FalsePositiveRecords.csv", row.names = FALSE, col.names = FALSE)
write.csv(output, "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, col.names = FALSE)
write.csv(output, "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", rownames = FALSE, colnames = FALSE)
write.csv(output, file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, col.names = FALSE)
write.csv(output, file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, col.names = FALSE)
write.csv(output, file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, col.names = FALSE, append = TRUE)
write.csv(output, file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, col.names = TRUE, append = TRUE)
write.csv(output, file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, append = TRUE)
write.csv(output, file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, append = TRUE)
write.csv(output[-1,], file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, append = TRUE)
write.table(output, file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, append = TRUE, col.names = FALSE, quote = FALSE, sep = ",")
write.table(output, file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, append = TRUE, col.names = FALSE, quote = FALSE, sep = ",")
write.table(output, file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, append = TRUE, col.names = FALSE, quote = FALSE, sep = ",")
write.table(output, file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, append = TRUE, col.names = FALSE, quote = FALSE, sep = ",")
write.table(output, file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, append = TRUE, col.names = FALSE, quote = FALSE, sep = ",")
write.table(output, file = "D:\\Study\\ITM\\IIP\\CIB - Task\\Data\\FalsePositiveRecords.csv", row.names = FALSE, append = TRUE, col.names = FALSE, quote = FALSE, sep = ",")
# This shows, actual value v/s predicted value
result <- data.frame(testData$quality, predict(rfModel, testData, type = "response"))
print(result)
predict(rfModel, testData, type = "response")
# This shows, actual value v/s predicted value
result <- data.frame(testData$quality, predict(rfModel, testData[1,], type = "response"))
predict(rfModel, testData[3,], type = "response")
predict(rfModel, testData[3,], type = "class")
predict(rfModel, testData[3,], type = "response")
View(testData)
View(testData)
testData[3,]
predict(rfModel, testData[3,])
?predict
help("predict")
predict(rfModel, testData[5,])
testData[5,]
predict(rfModel, testData[5,])[2]
predict(rfModel, testData[5,])[2,]
test <- predict(rfModel, testData[5,])
test
class(test)
test[0]
test
print(test)
test[,1]
as.vector(test)
test
as.numeric(test)
test
as.numeric(test)
as.vector(test)
as.numeric(as.vector(test))
as.integer(test)
View(result)
myTest <- predict(rfModel, testData[10,])
myTest
testData[10, ]
View(testData)
as.vector(myTest)
as.numeric(myTest)
iris
iris[3:,]
iris[3:]
iris[-1:-2,]
select(iris, -c("Petal.Length"))
select(iris, c(-"Petal.Length"))
library(class)
library(scorecard)
library(factoextra)
library(e1071)
select(iris, c("Petal.Length"))
library(caTools)
?select
library(dplyr)
select(iris, c(-"Petal.Length"))
select(iris, -c("Petal.Length"))
select(iris, -c("Petal.Length", "Petal.Width"))
paste("Data not found for account number", 1234, " with InBound Type: ", T)
paste("Data not found for account number", 1234, "with InBound Type: ", T)
cat("Random Forest evaluation -\n", "Is False Positive - TRUE\n", "Sent to Supervisor\n")
